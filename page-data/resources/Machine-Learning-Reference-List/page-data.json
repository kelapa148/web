{"componentChunkName":"component---src-templates-resource-template-js","path":"/resources/Machine-Learning-Reference-List","result":{"data":{"site":{"siteMetadata":{"title":"#COCONUT"}},"markdownRemark":{"html":"<h1>Machine Learning Reference List</h1>\n<p>Here's a curated list of references/resources that you can use to teach yourself Machine Learning, annotated with prerequisites and recommendations to help you choose. It's a work in progress and I'll be updating it every so often, so be sure to keep checking!</p>\n<h1>Courses</h1>\n<p>A list of highly recommended short courses and lecture video series.</p>\n<h2>Mathematics for Machine Learning</h2>\n<p>Machine Learning requires some mathematical prerequisites for you to understand what's going on. Generally, experience with statistics, probability, linear algebra, and multivariate calculus are hard requirements. Reading papers and books is hard without the prerequisites, so we cannot stress how important it is to go through them first! If you're pressed with time, I recommend running through just CMU 10-606. Otherwise, the other things listed would provide really good resources. </p>\n<table>\n<thead>\n<tr>\n<th align=\"left\">Course</th>\n<th align=\"left\">Source</th>\n<th align=\"left\">Notes</th>\n<th align=\"left\">Prerequisites</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td align=\"left\"><a href=\"https://www.youtube.com/playlist?list=PL7y-1rk2cCsAqRtWoZ95z-GMcecVG5mzA\">[10-606] Mathematical Background for Machine Learning</a></td>\n<td align=\"left\">Carnegie Mellon University</td>\n<td align=\"left\">Teaches the mathematical foundations. Take this if unsure where to go. No needed prior knowledge, but previous classes on statistics, linear algebra, and calculus would help.</td>\n<td align=\"left\">None.</td>\n</tr>\n<tr>\n<td align=\"left\"><a href=\"https://www.youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab\">Essence of Linear Algebra</a></td>\n<td align=\"left\">3Blue1Brown</td>\n<td align=\"left\">My favorite linear algebra short course online, with an emphasis on geometric interpretations and intuitions. Recommended binge watch.</td>\n<td align=\"left\">None.</td>\n</tr>\n<tr>\n<td align=\"left\"><a href=\"http://www.fast.ai/2017/07/17/num-lin-alg/\">Computational Linear Algebra</a></td>\n<td align=\"left\">fast.ai</td>\n<td align=\"left\">A more practical linear algebra class with emphasis on practical intuition and coding. Teaches you how to code the algorithms for those who like to see numbers in action.</td>\n<td align=\"left\">None.</td>\n</tr>\n<tr>\n<td align=\"left\"><a href=\"http://www.cs.cmu.edu/~zkolter/course/linalg/index.html\">Linear Algebra Review</a></td>\n<td align=\"left\">Carnegie Mellon University</td>\n<td align=\"left\">A quick review on the guts of linear algebra. Only take it if you've taken a previous course.</td>\n<td align=\"left\">Previous linear algebra course.</td>\n</tr>\n<tr>\n<td align=\"left\"><a href=\"http://www.stat.cmu.edu/~larry/=stat705/\">[10-705] Intermediate Statistics</a></td>\n<td align=\"left\">Carnegie Mellon University</td>\n<td align=\"left\">Works nicely as a theoretical take on statistical theory. Coers topics such as bayesian inference and nonparametric testing. This is not a basic statistics course, and is intended for a deep dive in intermediate statistics! Recommended for intermediate students.</td>\n<td align=\"left\">Previous statistics and probability course.</td>\n</tr>\n</tbody>\n</table>\n<h2>Introduction to Machine Learning</h2>\n<p>Basic Machine Learning. Assumes the required mathematical background is met, ideally CMU 10-606 has been taken as a precursor. Go take CMU 10-701 if unsure where to go. </p>\n<table>\n<thead>\n<tr>\n<th align=\"left\">Course</th>\n<th align=\"left\">Source</th>\n<th align=\"left\">Notes</th>\n<th align=\"left\">Prerequisites</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td align=\"left\"><a href=\"http://www.cs.cmu.edu/~mgormley/courses/10701-f16/schedule.html\">[10-701] Introduction to Machine Learning</a></td>\n<td align=\"left\">Carnegie Mellon University</td>\n<td align=\"left\">My current go-to recommendation for an introduction to machine learning. Solid offering.</td>\n<td align=\"left\">Statistics, linear algebra, and calculus (multivariate). CMU 10-606 would work as a precursor.</td>\n</tr>\n<tr>\n<td align=\"left\"><a href=\"https://www.youtube.com/playlist?list=PLA89DCFA6ADACE599\">[CS229] Introduction to Machine Learning</a></td>\n<td align=\"left\">Stanford University</td>\n<td align=\"left\">Used to be my go-to, but is outdated (the video quality says it all). Go to CMU 10-701 unless you like seeing Andrew Ng prove theorems on six blackboards at once.</td>\n<td align=\"left\">Statistics, linear algebra, and calculus (multivariate). CMU 10-606 would work as a precursor.</td>\n</tr>\n<tr>\n<td align=\"left\"><a href=\"https://www.youtube.com/playlist?list=PLuz4CTPOUNi644ypoxzP1frkPYVHdjDJU\">[CS155] Introduction to Machine Learning</a></td>\n<td align=\"left\">California Institute of Technology</td>\n<td align=\"left\">Caltech's intro to machine learning, which Stan recommends. Yisong Yue teaches really well.</td>\n<td align=\"left\">Statistics, linear algebra, and calculus (multivariate). CMU 10-606 would work as a precursor.</td>\n</tr>\n</tbody>\n</table>\n<h2>Deep Learning</h2>\n<p>Neural networks and everything under it's umbrella. Requires good foundations! Some background in basic machine learning would help. Go take Hugo Larochelle's course for a more theoretical (proof-based) introduction.</p>\n<table>\n<thead>\n<tr>\n<th align=\"left\">Course</th>\n<th align=\"left\">Source</th>\n<th align=\"left\">Notes</th>\n<th align=\"left\">Prerequisites</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td align=\"left\"><a href=\"https://www.youtube.com/watch?v=SGZ6BttHMPw&#x26;list=PL6Xpj9I5qXYEcOhn7TqghAJ6NAPrNmUBH\">Neural Networks</a></td>\n<td align=\"left\">Universit√® de Sherbrooke</td>\n<td align=\"left\">Hugo Larochelle's neural networks class. My go-to recommendation for people who want a good theory-based introduction with complete proofs and intuitions.</td>\n<td align=\"left\">Good linear algebra and multivariate calculus, plus statistics and information theory.</td>\n</tr>\n<tr>\n<td align=\"left\"><a href=\"https://www.cs.toronto.edu/~hinton/coursera_lectures.html\">Neural Networks</a></td>\n<td align=\"left\">Coursera</td>\n<td align=\"left\">The coursera neural networks course from the godfather Geoffrey Hinton himself!</td>\n<td align=\"left\">Good linear algebra and multivariate calculus, plus statistics and information theory.</td>\n</tr>\n<tr>\n<td align=\"left\"><a href=\"https://www.youtube.com/watch?v=aircAruvnKk&#x26;list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi\">Neural Networks</a></td>\n<td align=\"left\">3Blue1Brown</td>\n<td align=\"left\">Not an in-depth deep learning course but rather a series of videos that help you visualize and understand the intuitions and mechanics behind neural networks. Recommended binge-watch! Can be used as a primer to get your feet wet.</td>\n<td align=\"left\">Just calculus is fine.</td>\n</tr>\n</tbody>\n</table>\n<h2>Natural Language Processing</h2>\n<p>Courses on Natural Language Processing (with an emphasis on deep learning methods). I learned from the old CS224N course, but we've added the new one here.</p>\n<table>\n<thead>\n<tr>\n<th align=\"left\">Course</th>\n<th align=\"left\">Source</th>\n<th align=\"left\">Notes</th>\n<th align=\"left\">Prerequisites</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td align=\"left\"><a href=\"https://www.youtube.com/watch?v=8rXD5-xhemo&#x26;list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z\">[CS224N] Introduction to Natural Language Processing with Deep Learning</a></td>\n<td align=\"left\">Stanford University</td>\n<td align=\"left\">The Winter 2019 version of the Deep Learning + NLP course offered by Christopher Manning and Abigail See. Highly recommended.</td>\n<td align=\"left\">A previous machine learning course. A previous deep learning course is appreciated.</td>\n</tr>\n<tr>\n<td align=\"left\"><a href=\"https://www.youtube.com/playlist?list=PLqdrfNEc5QnuV9RwUAhoJcoQvu4Q46Lja\">[CS224N] Introduction to Natural Language Processing with Deep Learning</a></td>\n<td align=\"left\">Stanford University</td>\n<td align=\"left\">The older, time-tested version of the CS224N course, added here in case you need it.</td>\n<td align=\"left\">A previous machine learning course. A previous deep learning course is appreciated.</td>\n</tr>\n</tbody>\n</table>\n<h2>Computer Vision</h2>\n<p>Courses on Computer Vision (with an emphasis on deep learning methods).</p>\n<table>\n<thead>\n<tr>\n<th align=\"left\">Course</th>\n<th align=\"left\">Source</th>\n<th align=\"left\">Notes</th>\n<th align=\"left\">Prerequisites</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td align=\"left\"><a href=\"https://www.youtube.com/playlist?list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv\">[CS231N] Convolutional Neural Networks for Visual Recognition</a></td>\n<td align=\"left\">Stanford University</td>\n<td align=\"left\">Stanford's computer vision class with an emphasis on deep learning techniques. Taught by Fei-Fei Li, Justin Johnson, and Serena Yeung.</td>\n<td align=\"left\">A previous machine learning course. A previous deep learning course is appreciated.</td>\n</tr>\n</tbody>\n</table>\n<h2>Data Science</h2>\n<p>We're actually making some data science lecture videos so watch this space as it's coming soon!</p>\n<h1>Books</h1>\n<p>Some of my highly recommended books. </p>\n<h2>Machine Learning and Deep Learning</h2>\n<ul>\n<li><a href=\"https://github.com/dlsucomet/MLResources/blob/master/books/Deep%20Learning.pdf\">Deep Learning</a> by Ian Goodfellow, Yoshua Bengio, and Aaron Courville (2016) - Written by some of the greatest names in AI Research today, this book is the best I can recommend for an introduction to Deep Learning.</li>\n<li><a href=\"https://github.com/dlsucomet/MLResources/blob/master/books/Pattern%20Recognition%20and%20Machine%20Learning.pdf\">Pattern Recognition and Machine Learning</a> by Christopher Bishop (2006) - The OG Machine Learning Book. A tad bit outdated, but it does work really great as a classical machine learning textbook.</li>\n</ul>\n<h2>Data Science</h2>\n<ul>\n<li><a href=\"https://jakevdp.github.io/PythonDataScienceHandbook/\">Python Data Science Handbook</a> The book introduces the core libraries essential for working with data in Python: particularly IPython, NumPy, Pandas, Matplotlib, Scikit-Learn</li>\n</ul>\n<h1>Conference and Journal Papers</h1>\n<p>We're making a separate list of good papers to read. Coming soon!</p>\n<h1>Blogs and Podcasts</h1>\n<p>A collection of blogs, blog posts, and podcasts that talk ML and Deep Learning.</p>\n<h2>Websites and Trackers</h2>\n<ul>\n<li><a href=\"https://paperswithcode.com\">Papers With Code</a> - A tracker with SOTA leaderboards for multiple tasks in different areas of research.</li>\n<li><a href=\"http://nlpprogress.com\">Tracking The Progress of NLP</a> - A tracker that's regular updated with the state-of-the-art in various NLP tasks, datasets, techniques, etc.</li>\n</ul>\n<h2>Blog Posts</h2>\n<ul>\n<li><a href=\"http://explained.ai/matrix-calculus/index.html\">The Matrix Calculus You Need For Deep Learning</a> - A \"paper\" attempting to explain all the matrix calculus you need to understand deep learning. The learning curve might be a tad bit too steep so I suggest it as a side-material when taking a math course.</li>\n<li><a href=\"https://medium.com/huggingface/universal-word-sentence-embeddings-ce48ddc8fc3a\">The Best of Universal Sentence/Word Embeddings</a> - From the blog of Thomas Wolf, an NLP-Deep Learning researcher. Reviews the current state-of-the-art techniques in word embedding and sentence embedding techniques.</li>\n</ul>","frontmatter":{"date":"July 12, 2022","path":"/resources/Machine-Learning-Reference-List","title":"Machine Learning Reference List","thumbnail":"","metaDescription":"Here's a curated list of references/resources that you can use to teach yourself Machine Learning."}}},"pageContext":{}},"staticQueryHashes":["3159585216","440143384"]}